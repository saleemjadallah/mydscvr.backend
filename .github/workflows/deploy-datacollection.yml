name: Deploy DataCollection to Production

on:
  push:
    branches: [main]
    paths: ['DataCollection/**']
  workflow_dispatch:

jobs:
  deploy:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Create DataCollection.env from secrets
      run: |
        cd DataCollection
        cat > DataCollection.env << EOF
        # DXB Events Data Collection Pipeline - Environment Variables
        
        # Environment Configuration
        ENVIRONMENT=production
        DEBUG=false
        LOG_LEVEL=INFO
        
        # MongoDB Configuration
        MONGO_URI=${{ secrets.MONGO_URI }}
        MONGO_USER=${{ secrets.MONGO_USER }}
        MONGO_PASSWORD=${{ secrets.MONGO_PASSWORD }}
        MONGO_DB_NAME=${{ secrets.MONGO_DB_NAME }}
        
        # Redis Configuration  
        REDIS_URL=redis://localhost:6379/0
        
        # API Keys (REQUIRED)
        FIRECRAWL_API_KEY=${{ secrets.FIRECRAWL_API_KEY }}
        PERPLEXITY_API_KEY=${{ secrets.PERPLEXITY_API_KEY }}
        
        # Google OAuth Configuration
        GOOGLE_CLIENT_ID=${{ secrets.GOOGLE_CLIENT_ID }}
        
        # Backend Integration
        BACKEND_API_URL=https://mydscvr.xyz
        BACKEND_WEBHOOK_URL=https://mydscvr.xyz/api/webhooks/events
        BACKEND_API_KEY=${{ secrets.BACKEND_API_KEY }}
        
        # Rate Limiting Settings
        FIRECRAWL_RATE_LIMIT=100
        PERPLEXITY_RATE_LIMIT=1000
        
        # Error Handling
        MAX_RETRY_ATTEMPTS=3
        RETRY_DELAY_SECONDS=5
        
        # Monitoring Configuration
        METRICS_PORT=8001
        ENABLE_MONITORING=true
        
        # Scraping Configuration
        DEFAULT_SCRAPING_TIMEOUT=30
        MAX_CONCURRENT_SCRAPERS=3
        RATE_LIMIT_DELAY=1
        
        # AI Processing Configuration
        AI_TEMPERATURE=0.7
        MAX_AI_RETRIES=3
        AI_TIMEOUT=30
        
        # Data Quality Thresholds
        MIN_QUALITY_SCORE=70
        ENABLE_FAMILY_ANALYSIS=true
        ENABLE_CONTENT_ENHANCEMENT=true
        EOF
        
    - name: Setup SSH
      run: |
        mkdir -p ~/.ssh
        echo "${{ secrets.SSH_PRIVATE_KEY }}" > ~/.ssh/id_rsa
        chmod 600 ~/.ssh/id_rsa
        ssh-keyscan -H ${{ secrets.SERVER_HOST }} >> ~/.ssh/known_hosts
        
    - name: Deploy DataCollection to server
      run: |
        cd DataCollection
        rsync -avz --exclude='venv' --exclude='__pycache__' --exclude='*.pyc' \
          --exclude='.git' --exclude='logs' --exclude='*.log' \
          -e "ssh -i ~/.ssh/id_rsa" \
          ./ ${{ secrets.DATACOLLECTION_USER }}@${{ secrets.SERVER_HOST }}:${{ secrets.DATACOLLECTION_PATH }}/
          
    - name: Install dependencies and restart services
      run: |
        ssh -i ~/.ssh/id_rsa ${{ secrets.DATACOLLECTION_USER }}@${{ secrets.SERVER_HOST }} '
          cd ${{ secrets.DATACOLLECTION_PATH }} &&
          source venv/bin/activate &&
          pip install -r requirements.txt --quiet &&
          echo "âœ… Dependencies updated"
        '
        
    - name: Test configuration
      run: |
        ssh -i ~/.ssh/id_rsa ${{ secrets.DATACOLLECTION_USER }}@${{ secrets.SERVER_HOST }} '
          cd ${{ secrets.DATACOLLECTION_PATH }} &&
          source venv/bin/activate &&
          python -c "
from config.perplexity_settings import get_settings
settings = get_settings()
print(f\"âœ… Perplexity API key loaded: {bool(settings.PERPLEXITY_API_KEY)}\")
print(f\"âœ… MongoDB URI loaded: {bool(settings.MONGO_URI)}\")
print(f\"âœ… Configuration test passed\")
          " 2>&1
        '
        
    - name: Verify cron jobs
      run: |
        ssh -i ~/.ssh/id_rsa ${{ secrets.DATACOLLECTION_USER }}@${{ secrets.SERVER_HOST }} '
          echo "ðŸ“‹ Current crontab:"
          crontab -l | grep -E "(enhanced_collection|hidden-gems|events)" || echo "No relevant cron jobs found"
          echo "âœ… Cron verification complete"
        '